# 黃金交叉 + 斐波那契 回測 + XGBoost + Walk-Forward + Multi-class Label
# 檔名：黃金交叉+斐波那契_FeaturePipeline_and_Backtester.py
# 目的：把 pipeline 改成 multi-class (short / hold / long)，使用 XGBoost multi-class 訓練，並在每個 walk-forward fold 上執行回測（支援多單與空單）。
# 輸出：
#  - xgb_model_fold{fold}.json (每個 fold 的 multi-class 模型)
#  - scaler_fold{fold}.pkl
#  - xgb_models/walkforward_report.csv
#  - xgb_models/wf_backtest_summary.csv

import os	
import math
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import joblib
import xgboost as xgb
import os
import requests
from zipfile import ZipFile
import io

# ------------------------------
# 0. Sample CSV generator (skip if you have real data)
# ------------------------------
def generate_monthly_urls(symbol, start_date, end_date):
    current = start_date
    urls = []
    while current <= end_date:
        url = f"https://data.binance.vision/data/futures/um/monthly/klines/{symbol}/15m/{symbol}-15m-{current.strftime('%Y-%m')}.zip"
        urls.append((url, current.strftime('%Y-%m')))
        if current.month == 12:
            current = current.replace(year=current.year + 1, month=1, day=1)
        else:
            current = current.replace(month=current.month + 1, day=1)
    return urls

def download_and_extract_zip(url):
    print(f"下載 {url} ...")
    r = requests.get(url, stream=True)
    if r.status_code != 200:
        print(f"下載失敗，狀態碼 {r.status_code}")
        return None
    with ZipFile(io.BytesIO(r.content)) as z:
        name_list = z.namelist()
        if len(name_list) == 0:
            print("壓縮包內沒有檔案")
            return None
        with z.open(name_list[0]) as f:
            df = pd.read_csv(f)  # 自動判斷header
    return df

def complete_csv(symbol = "ETHUSDT",start_date = datetime(2023, 1, 1),end_date = datetime(2025, 8, 1)):

    urls = generate_monthly_urls(symbol, start_date, end_date)
    all_dfs = []

    for url, ym in urls:
        df = download_and_extract_zip(url)
        if df is not None and not df.empty:
            print(f"{ym} 資料樣本:")
            print(df.head())
            all_dfs.append(df)
        else:
            print(f"{ym} 資料下載失敗或為空，跳過。")

    if not all_dfs:
        print("沒有任何資料被下載，程式結束。")
        return

    combined_df = pd.concat(all_dfs, ignore_index=True)

    # 檢查欄位名稱是否存在
    if 'open_time' in combined_df.columns:
        try:
            combined_df['open_time'] = pd.to_datetime(combined_df['open_time'], unit='ms')
        except Exception as e:
            print(f"轉換時間欄位錯誤: {e}")
    else:
        print("找不到 'open_time' 欄位，請確認資料格式。")

    combined_df = combined_df.sort_values('open_time').reset_index(drop=True)

    print(f"總共合併 {len(combined_df)} 筆資料。")

    output_file = f'{symbol}_15m_klines_merged.csv'
    combined_df.rename(columns={'open_time':'timestamp'}, inplace=True)
    combined_df.to_csv(output_file, index=False)

    
    print(f"合併後CSV檔案已儲存：{output_file}")

    return combined_df, output_file

# ------------------------------
# 1. Indicators
# ------------------------------

def SMA(series, n):
    return series.rolling(n, min_periods=1).mean()


def ATR(df, n=14):
    high_low = df['high'] - df['low']
    high_close = (df['high'] - df['close'].shift()).abs()
    low_close = (df['low'] - df['close'].shift()).abs()
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    return tr.rolling(n, min_periods=1).mean()


def RSI(series, n=14):
    delta = series.diff()
    up = delta.clip(lower=0)
    down = -1 * delta.clip(upper=0)
    ma_up = up.rolling(n, min_periods=1).mean()
    ma_down = down.rolling(n, min_periods=1).mean()
    rs = ma_up / (ma_down + 1e-9)
    return 100 - (100 / (1 + rs))

# ------------------------------
# 2. Swing & Fibonacci
# ------------------------------

def detect_swing_high_low(df, lookback=240):
    df['swing_high'] = df['high'].rolling(lookback, min_periods=1).max()
    df['swing_low'] = df['low'].rolling(lookback, min_periods=1).min()
    return df


def fib_levels(row):
    high = row['swing_high']
    low = row['swing_low']
    span = high - low
    if span <= 0 or pd.isna(span):
        return {}
    ratios = [0.0, 0.236, 0.382, 0.5, 0.618, 0.786, 1.0]
    out = {}
    for r in ratios:
        out[f'fib_{int(r*1000)}'] = high - r * span
    return out

# ------------------------------
# 3. Feature pipeline
# ------------------------------

def build_features(df, ma_short=50, ma_long=200, atr_n=14, rsi_n=14, swing_lookback=240):
    df = df.copy()
    df = df.sort_values('timestamp').reset_index(drop=True)
    df['ma_s'] = SMA(df['close'], ma_short)
    df['ma_l'] = SMA(df['close'], ma_long)
    df['ma_diff'] = df['ma_s'] - df['ma_l']
    df['ma_diff_pct'] = df['ma_diff'] / (df['ma_l'] + 1e-9)
    df['ma_slope'] = df['ma_s'].diff()
    df['atr'] = ATR(df, n=atr_n)
    df['rsi'] = RSI(df['close'], n=rsi_n)
    df = detect_swing_high_low(df, lookback=swing_lookback)
    fibs = df.apply(fib_levels, axis=1)
    fib_df = pd.DataFrame(list(fibs.values), index=fibs.index).fillna(method='ffill')
    df = pd.concat([df, fib_df], axis=1)
    fib_cols = [c for c in df.columns if c.startswith('fib_')]
    if len(fib_cols) > 0:
        df['closest_fib_dist_pct'] = (np.abs(df['close'].values.reshape(-1,1) - df[fib_cols].values)).min(axis=1) / (df['close'] + 1e-9)
    else:
        df['closest_fib_dist_pct'] = np.nan
    df['ma_diff_prev'] = df['ma_diff'].shift(1)
    df['golden_cross'] = ((df['ma_diff_prev'] < 0) & (df['ma_diff'] > 0)).astype(int)
    df['death_cross'] = ((df['ma_diff_prev'] > 0) & (df['ma_diff'] < 0)).astype(int)
    df = df.dropna().reset_index(drop=True)
    return df

# ------------------------------
# 4. Labeling: multi-class (-1 short, 0 hold, 1 long)
#    - future_bars: lookahead
#    - up_thresh & down_thresh: thresholds for labeling
# ------------------------------

def make_labels_multiclass(df, future_bars=30, up_thresh=0.002, down_thresh=-0.002):
    df = df.copy()
    df['future_close'] = df['close'].shift(-future_bars)
    df['future_ret'] = (df['future_close'] - df['close']) / df['close']
    df = df[:-future_bars].copy()
    # label mapping: 0=short, 1=hold, 2=long (for xgboost multi)
    labels = np.where(df['future_ret'] > up_thresh, 2, np.where(df['future_ret'] < down_thresh, 0, 1))
    df['label_mc'] = labels
    return df

# ------------------------------
# 5. Walk-forward training (multi-class)
# ------------------------------

def walk_forward_train_multiclass(df, feature_cols, initial_train_size=2000, test_size=1000, max_folds=10, model_dir='xgb_models_mc'):
    os.makedirs(model_dir, exist_ok=True)
    results = []
    n = len(df)
    fold = 0
    train_end = initial_train_size
    while train_end + test_size <= n and fold < max_folds:
        fold += 1
        print(f"=== Fold {fold}: train [0:{train_end}] test [{train_end}:{train_end+test_size}] ===")
        train_df = df.iloc[0:train_end].copy()
        test_df = df.iloc[train_end:train_end+test_size].copy()
        X_train = train_df[feature_cols].values
        y_train = train_df['label_mc'].values
        X_test = test_df[feature_cols].values
        y_test = test_df['label_mc'].values
        scaler = StandardScaler()
        X_train_s = scaler.fit_transform(X_train)
        X_test_s = scaler.transform(X_test)
        dtrain = xgb.DMatrix(X_train_s, label=y_train)
        dtest = xgb.DMatrix(X_test_s, label=y_test)
        params = {
            'objective': 'multi:softprob',
            'num_class': 3,
            'eval_metric': 'mlogloss',
            'max_depth': 6,
            'eta': 0.05,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'seed': 42
        }
        watchlist = [(dtrain, 'train'), (dtest, 'eval')]
        bst = xgb.train(params, dtrain, num_boost_round=500, evals=watchlist, early_stopping_rounds=20, verbose_eval=False)
        # predict
        yprob = bst.predict(dtest)  # shape (n,3)
        ypred = np.argmax(yprob, axis=1)
        acc = accuracy_score(y_test, ypred)
        # compute per-class precision/recall/f1 if desired
        print(f"fold {fold} -> acc {acc:.4f}")
        # save model and scaler
        model_path = os.path.join(model_dir, f'xgb_model_fold{fold}.json')
        scaler_path = os.path.join(model_dir, f'scaler_fold{fold}.pkl')
        bst.save_model(model_path)
        joblib.dump(scaler, scaler_path)
        # store metrics
        results.append({
            'fold': fold,
            'train_end_idx': train_end,
            'test_start_idx': train_end,
            'test_end_idx': train_end+test_size,
            'acc': acc
        })
        # expand window
        train_end = train_end + test_size
    res_df = pd.DataFrame(results)
    res_df.to_csv(os.path.join(model_dir, 'walkforward_report.csv'), index=False)
    print('Walk-forward (multi-class) finished. Reports saved in', model_dir)
    return res_df

# ------------------------------
# 6. Backtester that handles long & short from multi-class predictions
#    - loads xgb multi-class model & scaler
#    - decision rule: require golden cross direction filter for longs; symmetric for shorts
# ------------------------------

class MultiClassPerpBacktester:
    def __init__(self, df, model_path, scaler_path, feature_cols, cap=10000.0, leverage=20,
                 fee_pct=0.0004, slippage_pct=0.0005, per_trade_risk=0.02, prob_thresh=0.5):
        self.df = df.reset_index(drop=True)
        self.model_path = model_path
        self.scaler_path = scaler_path
        self.feature_cols = feature_cols
        self.cap_init = cap
        self.cap = cap
        self.equity = cap
        self.leverage = leverage
        self.fee_pct = fee_pct
        self.slippage_pct = slippage_pct
        self.per_trade_risk = per_trade_risk
        self.prob_thresh = prob_thresh
        # load model & scaler
        self.bst = xgb.Booster()
        self.bst.load_model(model_path)
        self.scaler = joblib.load(scaler_path)
        self.positions = []
        self.trades = []
        self.peak_equity = cap
        self.drawdown_pause = 0.05
        self.hard_stop_loss = 0.10
        self.paused = False
        self.stopped = False

    def _predict_probs(self, Xrow):
        Xs = self.scaler.transform(Xrow.reshape(1,-1))
        d = xgb.DMatrix(Xs)
        p = self.bst.predict(d)[0]  # length 3
        # returns dict: {0:prob_short, 1:prob_hold, 2:prob_long}
        return {0: p[0], 1: p[1], 2: p[2]}

    def _size_from_risk(self, price, p_stop):
        cap_risk = self.cap * self.per_trade_risk
        notional = cap_risk / p_stop if p_stop>0 else 0
        notional = min(notional, self.cap * 5)
        qty = notional / price
        initial_margin = notional / self.leverage
        return {'notional': notional, 'qty': qty, 'initial_margin': initial_margin}

    def run(self, p_stop_pct_long=0.01, p_stop_pct_short=0.01):
        for i in range(len(self.df)):
            if self.stopped:
                break
            row = self.df.loc[i]
            price = row['close']
            # update unrealized pnl & stops
            self._update_mtms(i)
            # risk checks
            self.peak_equity = max(self.peak_equity, self.equity)
            drawdown = (self.peak_equity - self.equity) / (self.peak_equity + 1e-9)
            if drawdown > self.drawdown_pause:
                self.paused = True
            if (self.cap_init - self.equity) / (self.cap_init + 1e-9) >= self.hard_stop_loss:
                self._close_all(i)
                self.stopped = True
                print('HARD STOP triggered during backtest')
                break
            if self.paused:
                continue
            Xrow = row[self.feature_cols].values
            probs = self._predict_probs(Xrow)
            pred = max(probs, key=probs.get)  # predicted class 0/1/2
            p_val = probs[pred]
            # apply hard direction filters: for longs require MA_short > MA_long; for shorts require MA_short < MA_long
            if pred == 2 and p_val > self.prob_thresh and row['ma_s'] > row['ma_l']:
                # enter long
                entry_price = price * (1 + self.slippage_pct)
                p_stop = p_stop_pct_long
                sizing = self._size_from_risk(entry_price, p_stop)
                if sizing['notional']<=0:
                    continue
                qty = sizing['qty']
                stop_price = entry_price * (1 - p_stop)
                fee = sizing['notional'] * self.fee_pct
                self.cap -= sizing['initial_margin']
                pos = {'side':'long','entry_idx':i,'entry_price':entry_price,'qty':qty,'notional':sizing['notional'],'stop_price':stop_price,'open':True,'fee':fee,'initial_margin':sizing['initial_margin']}
                self.positions.append(pos)
                self.trades.append({'type':'entry_long','idx':i,'price':entry_price,'notional':sizing['notional'],'fee':fee})
            elif pred == 0 and p_val > self.prob_thresh and row['ma_s'] < row['ma_l']:
                # enter short (simulate symmetric perp short)
                entry_price = price * (1 - self.slippage_pct)
                p_stop = p_stop_pct_short
                sizing = self._size_from_risk(entry_price, p_stop)
                if sizing['notional']<=0:
                    continue
                qty = sizing['qty']
                stop_price = entry_price * (1 + p_stop)
                fee = sizing['notional'] * self.fee_pct
                self.cap -= sizing['initial_margin']
                pos = {'side':'short','entry_idx':i,'entry_price':entry_price,'qty':qty,'notional':sizing['notional'],'stop_price':stop_price,'open':True,'fee':fee,'initial_margin':sizing['initial_margin']}
                self.positions.append(pos)
                self.trades.append({'type':'entry_short','idx':i,'price':entry_price,'notional':sizing['notional'],'fee':fee})
            else:
                # predicted hold or didn't meet threshold — do nothing
                continue
        # finalize: close remaining positions at last price
        self._close_all(len(self.df)-1)
        return {'initial_cap': self.cap_init, 'final_equity': self.equity, 'trades': self.trades}

    def _update_mtms(self, i):
        price = self.df.loc[i,'close']
        # unreal pnl for longs and shorts
        unreal = 0.0
        for p in self.positions:
            if not p['open']: continue
            if p['side']=='long':
                unreal += (price - p['entry_price']) * p['qty']
            else:
                # short: profit when price falls
                unreal += (p['entry_price'] - price) * p['qty']
        self.equity = self.cap + unreal
        # check stops
        for p in list(self.positions):
            if not p['open']: continue
            if p['side']=='long' and price <= p['stop_price']:
                exit_price = p['stop_price'] * (1 - self.slippage_pct)
                pnl = (exit_price - p['entry_price']) * p['qty']
                fee = p['notional'] * self.fee_pct
                self.equity += pnl - fee
                self.cap += p.get('initial_margin',0)
                p['open'] = False
                self.trades.append({'type':'stop_long','idx':i,'price':exit_price,'pnl':pnl,'fee':fee})
            if p['side']=='short' and price >= p['stop_price']:
                exit_price = p['stop_price'] * (1 + self.slippage_pct)
                pnl = (p['entry_price'] - exit_price) * p['qty']
                fee = p['notional'] * self.fee_pct
                self.equity += pnl - fee
                self.cap += p.get('initial_margin',0)
                p['open'] = False
                self.trades.append({'type':'stop_short','idx':i,'price':exit_price,'pnl':pnl,'fee':fee})
        # remove closed
        self.positions = [p for p in self.positions if p['open']]

    def _close_all(self, i):
        price = self.df.loc[i,'close']
        for p in self.positions:
            if not p['open']: continue
            if p['side']=='long':
                exit_price = price * (1 - self.slippage_pct)
                pnl = (exit_price - p['entry_price']) * p['qty']
            else:
                exit_price = price * (1 + self.slippage_pct)
                pnl = (p['entry_price'] - exit_price) * p['qty']
            fee = p['notional'] * self.fee_pct
            self.equity += pnl - fee
            self.cap += p.get('initial_margin',0)
            p['open'] = False
            self.trades.append({'type':'close','idx':i,'price':exit_price,'pnl':pnl,'fee':fee})
        self.positions = []

# ------------------------------
# 7. Full flow: build features -> multi-class label -> walk-forward train -> per-fold backtest
# ------------------------------

def full_walkforward_multiclass(csv_path='ETHUSDT_15m_klines_merged.csv', initial_train_size=2000, test_size=1000, max_folds=5, model_dir='xgb_models_mc'):
    if not os.path.exists(csv_path):
        df, out_file = complete_csv(symbol = "ETHUSDT",start_date = datetime(2023, 1, 1),end_date = datetime(2025, 8, 1))
        csv_path = out_file
    else:
        df = pd.read_csv(csv_path, parse_dates=['timestamp'])

    df_feat = build_features(df)
    df_lab = make_labels_multiclass(df_feat, future_bars=30, up_thresh=0.002, down_thresh=-0.002)
    feature_cols = ['ma_s', 'ma_l', 'ma_diff_pct', 'ma_slope', 'atr', 'rsi', 'closest_fib_dist_pct']
    df_lab = df_lab.dropna().reset_index(drop=True)
    os.makedirs(model_dir, exist_ok=True)
    n = len(df_lab)
    fold = 0
    train_end = initial_train_size
    overall_summary = []
    while train_end + test_size <= n and fold < max_folds:
        fold += 1
        print(f"Running fold {fold}")
        train_df = df_lab.iloc[0:train_end].copy()
        test_df = df_lab.iloc[train_end:train_end+test_size].copy()
        # train multi-class xgboost
        scaler = StandardScaler()
        X_train_s = scaler.fit_transform(train_df[feature_cols].values)
        dtrain = xgb.DMatrix(X_train_s, label=train_df['label_mc'].values)
        params = {'objective':'multi:softprob','num_class':3,'eval_metric':'mlogloss','max_depth':6,'eta':0.05,'subsample':0.8,'colsample_bytree':0.8,'seed':42}
        bst = xgb.train(params, dtrain, num_boost_round=500, verbose_eval=False)
        model_path = os.path.join(model_dir, f'xgb_model_fold{fold}.json')
        scaler_path = os.path.join(model_dir, f'scaler_fold{fold}.pkl')
        bst.save_model(model_path)
        joblib.dump(scaler, scaler_path)
        # backtest on test_df
        backtester = MultiClassPerpBacktester(test_df, model_path=model_path, scaler_path=scaler_path, feature_cols=feature_cols, cap=10000.0, leverage=20)
        stats = backtester.run(p_stop_pct_long=0.01, p_stop_pct_short=0.01)
        summary = {'fold':fold, 'initial_cap':stats['initial_cap'], 'final_equity':stats['final_equity'], 'n_trades':len(stats['trades'])}
        overall_summary.append(summary)
        print(f"Fold {fold} result: final_equity {stats['final_equity']:.2f}, trades {len(stats['trades'])}")
        # expand window
        train_end = train_end + test_size
    out_df = pd.DataFrame(overall_summary)
    out_df.to_csv(os.path.join(model_dir, 'wf_backtest_summary.csv'), index=False)
    print('Full multi-class walk-forward pipeline finished. Summaries saved in', model_dir)
    return out_df

# ------------------------------
# 8. Demo runnable
# ------------------------------
if __name__ == '__main__':
    print('Start full multi-class walk-forward pipeline demo...')
    summary = full_walkforward_multiclass(
    csv_path='ETHUSDT_15m_klines_merged.csv',
    initial_train_size=2000,
    test_size=1000,
    max_folds=5,
    model_dir='xgb_models_mc'
)
    
    print(summary)

# ------------------------------
# 設計說明與注意事項
# ------------------------------
# 1) Label mapping：0=short,1=hold,2=long（對應 xgboost 的 multi-class）。
# 2) 決策：模型輸出最大機率類別。額外的硬條件（MA方向）會被套用以降低錯誤方向交易。
# 3) Backtester 支援多單與空單的對稱模擬（簡化），實務請用 exchange 的精確盈虧計算式替換。
# 4) 風控：每筆風險預設 2% of cap；drawdown >5% -> 暫停新倉；cap 損失 ≥10% -> 平所有並停止。
# 5) 建議：把 future_bars、thresholds、feature set 做 grid search，並用 walk-forward 結果選參數。

# 下一步你要我做哪一項？（選一）：
# A: 把這個轉成 Colab-ready .ipynb 並附執行輸出。
# C: 把 backtester 的合約盈虧改為精準 perpetual math（含維持保證金與强平價格）。
# D: 幫你用真實 BTC/ETH/XRP/BNB 的 CSV 跑一次完整 multi-class walk-forward（請上傳 CSV）。
# 直接回 A 或 C 或 D。
